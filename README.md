# Twitter Sentiment Analysis Project

## Tá»•ng quan

Dá»± Ã¡n nÃ y tÃ¡i hiá»‡n vÃ  má»Ÿ rá»™ng nghiÃªn cá»©u vá» phÃ¢n tÃ­ch cáº£m xÃºc Twitter sá»­ dá»¥ng mÃ´ hÃ¬nh RoBERTa-Twitter, dá»±a trÃªn Ä‘á»“ Ã¡n gá»‘c cá»§a anh Thá»‹nh LÃ¢m Táº¥n. Thay vÃ¬ xÃ¢y dá»±ng láº¡i toÃ n bá»™ há»‡ thá»‘ng Big Data phá»©c táº¡p (Apache Kafka, Spark, MongoDB), chÃºng tÃ´i táº­p trung vÃ o viá»‡c tÃ¡i hiá»‡n mÃ´ hÃ¬nh AI vÃ  káº¿t quáº£ phÃ¢n tÃ­ch vá»›i dá»¯ liá»‡u má»›i.

## Kiáº¿n trÃºc ÄÆ¡n giáº£n hÃ³a

```
Raw Data Collection â†’ Text Preprocessing â†’ Sentiment Analysis â†’ Visualization
     (Twitter API)      (Text Cleaning)      (RoBERTa Model)     (Charts & Reports)
```

**So sÃ¡nh vá»›i Ä‘á»“ Ã¡n gá»‘c:**
- **Gá»‘c**: Producer â†’ Kafka â†’ Spark Streaming â†’ MongoDB â†’ Visualization
- **Hiá»‡n táº¡i**: Python Script â†’ CSV Files â†’ RoBERTa â†’ Charts & Reports

## TÃ­nh nÄƒng chÃ­nh

- ğŸ” **Thu tháº­p dá»¯ liá»‡u**: Tá»± Ä‘á»™ng crawl tweets vá»›i tá»« khÃ³a AI (GPT, ChatGPT, Copilot, etc.)
- ğŸ§¹ **Tiá»n xá»­ lÃ½**: LÃ m sáº¡ch vÄƒn báº£n (loáº¡i bá» URL, mentions, hashtags, kÃ½ tá»± Ä‘áº·c biá»‡t)
- ğŸ¤– **PhÃ¢n tÃ­ch cáº£m xÃºc**: Sá»­ dá»¥ng mÃ´ hÃ¬nh RoBERTa-Twitter tá»« Hugging Face
- ğŸ“Š **Trá»±c quan hÃ³a**: Táº¡o biá»ƒu Ä‘á»“ tÆ°Æ¡ng tá»± Ä‘á»“ Ã¡n gá»‘c (Figures 6.4, 6.5)
- ğŸ“ˆ **BÃ¡o cÃ¡o**: Thá»‘ng kÃª chi tiáº¿t vÃ  so sÃ¡nh káº¿t quáº£

## Cáº¥u trÃºc thÆ° má»¥c

```
sentiment-analysis-project/
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ config.py            # Cáº¥u hÃ¬nh chung
â”‚   â”œâ”€â”€ crawler.py           # Module thu tháº­p dá»¯ liá»‡u
â”‚   â”œâ”€â”€ data_preprocessing.py # Module tiá»n xá»­ lÃ½
â”‚   â”œâ”€â”€ sentiment_analysis.py # Module phÃ¢n tÃ­ch cáº£m xÃºc
â”‚   â”œâ”€â”€ visualization.py     # Module trá»±c quan hÃ³a
â”‚   â”œâ”€â”€ main.py             # Script chÃ­nh
â”‚   â””â”€â”€ __init__.py         # Package initialization
â”œâ”€â”€ data/                    # Dá»¯ liá»‡u thÃ´ vÃ  Ä‘Ã£ xá»­ lÃ½
â”œâ”€â”€ results/                 # Káº¿t quáº£ phÃ¢n tÃ­ch vÃ  biá»ƒu Ä‘á»“
â”œâ”€â”€ notebooks/              # Jupyter notebooks demo
â”œâ”€â”€ requirements.txt        # Danh sÃ¡ch thÆ° viá»‡n
â”œâ”€â”€ .env.example           # Template cho biáº¿n mÃ´i trÆ°á»ng
â””â”€â”€ README.md              # TÃ i liá»‡u nÃ y
```

## CÃ i Ä‘áº·t

### 1. Clone repository
```bash
git clone <repository-url>
cd sentiment-analysis-project
```

### 2. Táº¡o mÃ´i trÆ°á»ng áº£o (khuyáº¿n nghá»‹)
```bash
python -m venv venv
# Windows
venv\\Scripts\\activate
# Linux/Mac
source venv/bin/activate
```

### 3. CÃ i Ä‘áº·t thÆ° viá»‡n
```bash
pip install -r requirements.txt
```

### 4. Cáº¥u hÃ¬nh API Key
```bash
# Sao chÃ©p template
copy .env.example .env

# Chá»‰nh sá»­a file .env vÃ  thÃªm Twitter API key
TWITTER_API_KEY=your_api_key_here
```

## Sá»­ dá»¥ng

### Cháº¡y pipeline hoÃ n chá»‰nh
```bash
cd src
python main.py --mode full --keywords GPT ChatGPT Copilot --max-tweets 500
```

### PhÃ¢n tÃ­ch dá»¯ liá»‡u cÃ³ sáºµn
```bash
python main.py --mode analyze --data-file ../data/tweets_processed_20240101_120000.csv
```

### Sá»­ dá»¥ng tá»«ng module riÃªng láº»

#### 1. Thu tháº­p dá»¯ liá»‡u
```python
from src.crawler import TwitterCrawler

crawler = TwitterCrawler()
df = crawler.crawl_multiple_keywords(['GPT', 'ChatGPT'], max_tweets_per_keyword=100)
crawler.save_raw_data(df, 'my_tweets.csv')
```

#### 2. Tiá»n xá»­ lÃ½
```python
from src.data_preprocessing import TextPreprocessor

preprocessor = TextPreprocessor()
processed_df = preprocessor.preprocess_dataframe(df)
```

#### 3. PhÃ¢n tÃ­ch cáº£m xÃºc
```python
from src.sentiment_analysis import SentimentAnalyzer

analyzer = SentimentAnalyzer()
result_df = analyzer.analyze_dataframe(processed_df)
```

#### 4. Trá»±c quan hÃ³a
```python
from src.visualization import SentimentVisualizer

visualizer = SentimentVisualizer()
visualizer.create_all_visualizations(result_df)
```

## MÃ´ hÃ¬nh vÃ  PhÆ°Æ¡ng phÃ¡p

### MÃ´ hÃ¬nh RoBERTa-Twitter
- **Model**: `cardiffnlp/twitter-roberta-base-sentiment-latest`
- **Nguá»“n**: Hugging Face Transformers
- **Äáº·c Ä‘iá»ƒm**: ÄÆ°á»£c tinh chá»‰nh chuyÃªn biá»‡t cho dá»¯ liá»‡u Twitter
- **Output**: 3 lá»›p (Positive, Negative, Neutral) vá»›i confidence scores

### Pipeline Tiá»n xá»­ lÃ½ (theo Ä‘á»“ Ã¡n gá»‘c)
1. **Chuyá»ƒn chá»¯ thÆ°á»ng**: Chuáº©n hÃ³a text
2. **Loáº¡i bá» URL**: XÃ³a cÃ¡c liÃªn káº¿t web
3. **Loáº¡i bá» mentions**: XÃ³a @username
4. **Loáº¡i bá» hashtags**: XÃ³a #hashtag
5. **Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t**: Chá»‰ giá»¯ chá»¯ cÃ¡i vÃ  sá»‘
6. **Loáº¡i bá» khoáº£ng tráº¯ng thá»«a**: Chuáº©n hÃ³a spaces

### Tá»« khÃ³a thu tháº­p
```python
KEYWORDS = [
    "GPT", "Copilot", "Gemini",     # Tá»« Ä‘á»“ Ã¡n gá»‘c
    "GPT-4o", "Sora", "Llama 3",    # Tá»« khÃ³a má»›i
    "Claude", "ChatGPT"             # Bá»• sung thÃªm
]
```

## Káº¿t quáº£ vÃ  Biá»ƒu Ä‘á»“

Há»‡ thá»‘ng tá»± Ä‘á»™ng táº¡o cÃ¡c biá»ƒu Ä‘á»“ sau (tÆ°Æ¡ng tá»± Ä‘á»“ Ã¡n gá»‘c):

1. **Sentiment Distribution by Keyword**: Biá»ƒu Ä‘á»“ cá»™t chá»“ng thá»ƒ hiá»‡n tá»· lá»‡ cáº£m xÃºc theo tá»« khÃ³a
2. **Overall Sentiment Distribution**: Biá»ƒu Ä‘á»“ tá»•ng quan phÃ¢n bá»‘ cáº£m xÃºc
3. **Timeline Analysis**: Xu hÆ°á»›ng cáº£m xÃºc theo thá»i gian
4. **Interactive Dashboard**: Dashboard tÆ°Æ¡ng tÃ¡c báº±ng Plotly

## So sÃ¡nh vá»›i Äá»“ Ã¡n Gá»‘c

| Aspect | Äá»“ Ã¡n Gá»‘c | Dá»± Ã¡n Hiá»‡n táº¡i |
|--------|-----------|----------------|
| **Kiáº¿n trÃºc** | Big Data (Kafka + Spark + MongoDB) | Simple Python Pipeline |
| **MÃ´ hÃ¬nh** | RoBERTa-Twitter + Logistic Regression | RoBERTa-Twitter |
| **Thu tháº­p dá»¯ liá»‡u** | Real-time streaming | Batch collection |
| **Xá»­ lÃ½** | Spark Streaming + MLlib | Pandas + Transformers |
| **LÆ°u trá»¯** | MongoDB | CSV Files |
| **Triá»ƒn khai** | Distributed cluster | Single machine |
| **Phá»©c táº¡p** | High | Low |
| **Kháº£ nÄƒng má»Ÿ rá»™ng** | High | Medium |

## Káº¿t quáº£ Dá»± kiáº¿n

Dá»±a trÃªn Ä‘á»“ Ã¡n gá»‘c, chÃºng ta dá»± kiáº¿n:
- **Accuracy**: ~82% (tÆ°Æ¡ng Ä‘Æ°Æ¡ng káº¿t quáº£ gá»‘c)
- **Processing time**: Nhanh hÆ¡n do khÃ´ng cÃ³ overhead cá»§a distributed system
- **Resource usage**: Tháº¥p hÆ¡n Ä‘Ã¡ng ká»ƒ

## Troubleshooting

### Lá»—i thÆ°á»ng gáº·p

1. **ImportError: transformers**
   ```bash
   pip install transformers torch
   ```

2. **API Key khÃ´ng há»£p lá»‡**
   - Kiá»ƒm tra file `.env`
   - Äáº£m báº£o API key tá»« twitterapi.io Ä‘Ãºng format

3. **CUDA out of memory**
   ```python
   # Trong config.py, giáº£m BATCH_SIZE
   BATCH_SIZE = 16  # tá»« 32 xuá»‘ng 16
   ```

4. **Rate limit exceeded**
   ```python
   # TÄƒng RATE_LIMIT_DELAY trong config.py
   RATE_LIMIT_DELAY = 5  # tá»« 2s lÃªn 5s
   ```

## Development

### Cháº¡y tests
```bash
cd src
python -m pytest tests/  # (náº¿u cÃ³)
```

### Test tá»«ng module
```bash
python config.py      # Test configuration
python crawler.py     # Test data collection
python data_preprocessing.py  # Test preprocessing
python sentiment_analysis.py  # Test sentiment model
python visualization.py      # Test charts
```

## Káº¿ hoáº¡ch tÆ°Æ¡ng lai

- [ ] ThÃªm mÃ´ hÃ¬nh Logistic Regression Ä‘á»ƒ so sÃ¡nh
- [ ] Há»— trá»£ nhiá»u ngÃ´n ngá»¯
- [ ] Real-time dashboard vá»›i Streamlit
- [ ] Docker containerization
- [ ] Cloud deployment (AWS/Azure)
- [ ] A/B testing framework

## ÄÃ³ng gÃ³p

1. Fork repository
2. Táº¡o feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Táº¡o Pull Request

## License

MIT License - xem file LICENSE Ä‘á»ƒ biáº¿t chi tiáº¿t

## TÃ¡c giáº£

- **TÃªn cá»§a báº¡n** - *Initial work* - [GitHub](https://github.com/yourusername)
- **Tham kháº£o**: Äá»“ Ã¡n cá»§a Thá»‹nh LÃ¢m Táº¥n - Twitter Sentiment Analysis using Big Data

## Acknowledgments

- Cáº£m Æ¡n anh Thá»‹nh LÃ¢m Táº¥n vÃ¬ Ä‘á»“ Ã¡n tham kháº£o xuáº¥t sáº¯c
- Hugging Face team vÃ¬ mÃ´ hÃ¬nh RoBERTa-Twitter
- Cardiff NLP team vÃ¬ pre-trained model
- twitterapi.io vÃ¬ API service

---

*Dá»± Ã¡n nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n nhÆ° má»™t pháº§n cá»§a khÃ³a há»c NLP, tÃ¡i hiá»‡n vÃ  má»Ÿ rá»™ng nghiÃªn cá»©u vá» sentiment analysis vá»›i approach Ä‘Æ¡n giáº£n hÃ³a nhÆ°ng váº«n Ä‘áº£m báº£o cháº¥t lÆ°á»£ng káº¿t quáº£.*