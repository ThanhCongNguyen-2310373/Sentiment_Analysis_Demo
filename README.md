# Twitter Sentiment Analysis Project

## T·ªïng quan

D·ª± √°n n√†y t√°i hi·ªán v√† m·ªü r·ªông nghi√™n c·ª©u v·ªÅ ph√¢n t√≠ch c·∫£m x√∫c Twitter s·ª≠ d·ª•ng m√¥ h√¨nh RoBERTa-Twitter, d·ª±a tr√™n ƒë·ªì √°n g·ªëc c·ªßa anh Th·ªãnh L√¢m T·∫•n. Thay v√¨ x√¢y d·ª±ng l·∫°i to√†n b·ªô h·ªá th·ªëng Big Data ph·ª©c t·∫°p (Apache Kafka, Spark, MongoDB), ch√∫ng t√¥i t·∫≠p trung v√†o vi·ªác t√°i hi·ªán m√¥ h√¨nh AI v√† k·∫øt qu·∫£ ph√¢n t√≠ch v·ªõi d·ªØ li·ªáu m·ªõi.

## Ki·∫øn tr√∫c ƒê∆°n gi·∫£n h√≥a

```
Raw Data Collection ‚Üí Text Preprocessing ‚Üí Sentiment Analysis ‚Üí Visualization
     (Twitter API)      (Text Cleaning)      (RoBERTa Model)     (Charts & Reports)
```

**So s√°nh v·ªõi ƒë·ªì √°n g·ªëc:**
- **G·ªëc**: Producer ‚Üí Kafka ‚Üí Spark Streaming ‚Üí MongoDB ‚Üí Visualization
- **Hi·ªán t·∫°i**: Python Script ‚Üí CSV Files ‚Üí RoBERTa ‚Üí Charts & Reports

## T√≠nh nƒÉng ch√≠nh

- üîç **Thu th·∫≠p d·ªØ li·ªáu**: T·ª± ƒë·ªông crawl tweets v·ªõi t·ª´ kh√≥a AI (GPT, ChatGPT, Copilot, etc.)
- üßπ **Ti·ªÅn x·ª≠ l√Ω**: L√†m s·∫°ch vƒÉn b·∫£n (lo·∫°i b·ªè URL, mentions, hashtags, k√Ω t·ª± ƒë·∫∑c bi·ªát)
- ü§ñ **Ph√¢n t√≠ch c·∫£m x√∫c**: S·ª≠ d·ª•ng m√¥ h√¨nh RoBERTa-Twitter t·ª´ Hugging Face
- üìä **Tr·ª±c quan h√≥a**: T·∫°o bi·ªÉu ƒë·ªì t∆∞∆°ng t·ª± ƒë·ªì √°n g·ªëc (Figures 6.4, 6.5)
- üìà **B√°o c√°o**: Th·ªëng k√™ chi ti·∫øt v√† so s√°nh k·∫øt qu·∫£

## C·∫•u tr√∫c th∆∞ m·ª•c

```
sentiment-analysis-project/
‚îú‚îÄ‚îÄ src/                      # Source code
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # C·∫•u h√¨nh chung
‚îÇ   ‚îú‚îÄ‚îÄ crawler.py           # Module thu th·∫≠p d·ªØ li·ªáu
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.py # Module ti·ªÅn x·ª≠ l√Ω
‚îÇ   ‚îú‚îÄ‚îÄ sentiment_analysis.py # Module ph√¢n t√≠ch c·∫£m x√∫c
‚îÇ   ‚îú‚îÄ‚îÄ visualization.py     # Module tr·ª±c quan h√≥a
‚îÇ   ‚îú‚îÄ‚îÄ main.py             # Script ch√≠nh
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py         # Package initialization
‚îú‚îÄ‚îÄ data/                    # D·ªØ li·ªáu th√¥ v√† ƒë√£ x·ª≠ l√Ω
‚îú‚îÄ‚îÄ results/                 # K·∫øt qu·∫£ ph√¢n t√≠ch v√† bi·ªÉu ƒë·ªì
‚îú‚îÄ‚îÄ notebooks/              # Jupyter notebooks demo
‚îú‚îÄ‚îÄ requirements.txt        # Danh s√°ch th∆∞ vi·ªán
‚îú‚îÄ‚îÄ .env.example           # Template cho bi·∫øn m√¥i tr∆∞·ªùng
‚îî‚îÄ‚îÄ README.md              # T√†i li·ªáu n√†y
```

## Y√™u c·∫ßu h·ªá th·ªëng

### System Requirements
- **Python**: 3.8+ (ƒê√£ test tr√™n Python 3.13.7)
- **RAM**: T·ªëi thi·ªÉu 4GB, khuy·∫øn ngh·ªã 8GB+
- **Disk**: 2GB free space (cho models v√† data)
- **OS**: Windows 10/11, macOS, Linux
- **Internet**: C·∫ßn ƒë·ªÉ download models v√† API calls

### Package Dependencies
```
pandas>=1.5.0          # Data manipulation
numpy>=1.24.0           # Numerical computing  
torch>=2.0.0            # Deep learning framework
transformers>=4.30.0    # Hugging Face models
matplotlib>=3.7.0       # Basic plotting
seaborn>=0.12.0         # Statistical visualization
plotly>=5.15.0          # Interactive charts
requests>=2.31.0        # HTTP requests
python-dotenv>=1.0.0    # Environment variables
nltk>=3.8.0             # Natural language toolkit
jupyter>=1.0.0          # Notebook interface (optional)
```

## C√†i ƒë·∫∑t

### 1. Clone repository
```bash
git clone https://github.com/ThanhCongNguyen-2310373/Sentiment_Analysis_Demo.git
cd Sentiment_Analysis_Demo
```

### 2. T·∫°o m√¥i tr∆∞·ªùng ·∫£o (khuy·∫øn ngh·ªã)
```bash
# T·∫°o virtual environment
python -m venv .venv

# K√≠ch ho·∫°t environment
# Windows PowerShell:
.venv\Scripts\Activate.ps1
# Windows CMD:
.venv\Scripts\activate.bat
# Linux/Mac:
source .venv/bin/activate
```

### 3. C√†i ƒë·∫∑t c√°c package c·∫ßn thi·∫øt

#### Ph∆∞∆°ng ph√°p 1: C√†i ƒë·∫∑t t·ª´ requirements.txt (Khuy·∫øn ngh·ªã)
```bash
pip install -r requirements.txt
```

#### Ph∆∞∆°ng ph√°p 2: C√†i ƒë·∫∑t t·ª´ng package (Chi ti·∫øt)
```bash
# Core packages cho data processing
pip install pandas>=1.5.0
pip install numpy>=1.24.0

# Machine Learning v√† NLP
pip install torch>=2.0.0
pip install transformers>=4.30.0

# Visualization
pip install matplotlib>=3.7.0
pip install seaborn>=0.12.0
pip install plotly>=5.15.0

# API v√† networking
pip install requests>=2.31.0

# Environment management
pip install python-dotenv>=1.0.0

# Natural Language Processing utilities
pip install nltk>=3.8.0

# Optional: Jupyter for notebooks
pip install jupyter>=1.0.0
pip install ipykernel>=6.25.0
```

#### Ph∆∞∆°ng ph√°p 3: C√†i ƒë·∫∑t v·ªõi upgrade (N·∫øu g·∫∑p conflict)
```bash
pip install --upgrade pip
pip install --upgrade pandas numpy torch transformers matplotlib seaborn plotly requests python-dotenv nltk
```

### 4. C·∫•u h√¨nh API Key
```bash
# Sao ch√©p template
copy .env.template .env

# Ch·ªânh s·ª≠a file .env v√† th√™m Twitter API key t·ª´ twitterapi.io
TWITTER_API_KEY=your_api_key_here
TWITTER_BEARER_TOKEN=your_bearer_token_here
```

### 5. Ki·ªÉm tra c√†i ƒë·∫∑t
```bash
# Ki·ªÉm tra Python environment
python --version  # ƒê·∫£m b·∫£o >= 3.8

# Test import c√°c package ch√≠nh
python -c "import torch; print('PyTorch:', torch.__version__)"
python -c "import transformers; print('Transformers:', transformers.__version__)"
python -c "import pandas; print('Pandas:', pandas.__version__)"

# Ch·∫°y quick test
python quick_start.py
```

### 6. Download NLTK data (T·ª± ƒë·ªông khi ch·∫°y l·∫ßn ƒë·∫ßu)
```python
# S·∫Ω t·ª± ƒë·ªông download khi ch·∫°y, ho·∫∑c ch·∫°y manual:
import nltk
nltk.download('punkt')
nltk.download('stopwords')
```

## S·ª≠ d·ª•ng

### C√°ch nhanh nh·∫•t: Ch·∫°y demo
```bash
# Ch·∫°y demo v·ªõi sample data
python quick_start.py
```

### Ch·∫°y pipeline ho√†n ch·ªânh
```bash
# Ch·∫°y ph√¢n t√≠ch ho√†n ch·ªânh
python src/main.py

# Ho·∫∑c ch·∫°y v·ªõi custom settings
cd src
python main.py --keywords "GPT,ChatGPT,Copilot" --max-tweets 100
```

### S·ª≠ d·ª•ng Jupyter Notebook (T∆∞∆°ng t√°c)
```bash
# Kh·ªüi ƒë·ªông Jupyter
jupyter notebook

# M·ªü file: notebooks/twitter_sentiment_analysis_demo.ipynb
# Ch·∫°y t·ª´ng cell ƒë·ªÉ xem demo step-by-step
```

### S·ª≠ d·ª•ng t·ª´ng module ri√™ng l·∫ª

#### 1. Thu th·∫≠p d·ªØ li·ªáu
```python
from src.crawler import TwitterCrawler

crawler = TwitterCrawler()
df = crawler.crawl_multiple_keywords(['GPT', 'ChatGPT'], max_tweets_per_keyword=100)
crawler.save_raw_data(df, 'my_tweets.csv')
```

#### 2. Ti·ªÅn x·ª≠ l√Ω
```python
from src.data_preprocessing import TextPreprocessor

preprocessor = TextPreprocessor()
processed_df = preprocessor.preprocess_dataframe(df)
```

#### 3. Ph√¢n t√≠ch c·∫£m x√∫c
```python
from src.sentiment_analysis import SentimentAnalyzer

analyzer = SentimentAnalyzer()
result_df = analyzer.analyze_dataframe(processed_df)
```

#### 4. Tr·ª±c quan h√≥a
```python
from src.visualization import SentimentVisualizer

visualizer = SentimentVisualizer()
visualizer.create_all_visualizations(result_df)
```

## M√¥ h√¨nh v√† Ph∆∞∆°ng ph√°p

### M√¥ h√¨nh RoBERTa-Twitter
- **Model**: `cardiffnlp/twitter-roberta-base-sentiment-latest`
- **Ngu·ªìn**: Hugging Face Transformers
- **ƒê·∫∑c ƒëi·ªÉm**: ƒê∆∞·ª£c tinh ch·ªânh chuy√™n bi·ªát cho d·ªØ li·ªáu Twitter
- **Output**: 3 l·ªõp (Positive, Negative, Neutral) v·ªõi confidence scores

### Pipeline Ti·ªÅn x·ª≠ l√Ω (theo ƒë·ªì √°n g·ªëc)
1. **Chuy·ªÉn ch·ªØ th∆∞·ªùng**: Chu·∫©n h√≥a text
2. **Lo·∫°i b·ªè URL**: X√≥a c√°c li√™n k·∫øt web
3. **Lo·∫°i b·ªè mentions**: X√≥a @username
4. **Lo·∫°i b·ªè hashtags**: X√≥a #hashtag
5. **Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát**: Ch·ªâ gi·ªØ ch·ªØ c√°i v√† s·ªë
6. **Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a**: Chu·∫©n h√≥a spaces

### T·ª´ kh√≥a thu th·∫≠p
```python
KEYWORDS = [
    "GPT", "Copilot", "Gemini",     # T·ª´ ƒë·ªì √°n g·ªëc
    "GPT-4o", "Sora", "Llama 3",    # T·ª´ kh√≥a m·ªõi
    "Claude", "ChatGPT"             # B·ªï sung th√™m
]
```

## K·∫øt qu·∫£ v√† Bi·ªÉu ƒë·ªì

H·ªá th·ªëng t·ª± ƒë·ªông t·∫°o c√°c bi·ªÉu ƒë·ªì sau (t∆∞∆°ng t·ª± ƒë·ªì √°n g·ªëc):

1. **Sentiment Distribution by Keyword**: Bi·ªÉu ƒë·ªì c·ªôt ch·ªìng th·ªÉ hi·ªán t·ª∑ l·ªá c·∫£m x√∫c theo t·ª´ kh√≥a
2. **Overall Sentiment Distribution**: Bi·ªÉu ƒë·ªì t·ªïng quan ph√¢n b·ªë c·∫£m x√∫c
3. **Timeline Analysis**: Xu h∆∞·ªõng c·∫£m x√∫c theo th·ªùi gian
4. **Interactive Dashboard**: Dashboard t∆∞∆°ng t√°c b·∫±ng Plotly

## So s√°nh v·ªõi ƒê·ªì √°n G·ªëc

| Aspect | ƒê·ªì √°n G·ªëc | D·ª± √°n Hi·ªán t·∫°i |
|--------|-----------|----------------|
| **Ki·∫øn tr√∫c** | Big Data (Kafka + Spark + MongoDB) | Simple Python Pipeline |
| **M√¥ h√¨nh** | RoBERTa-Twitter + Logistic Regression | RoBERTa-Twitter |
| **Thu th·∫≠p d·ªØ li·ªáu** | Real-time streaming | Batch collection |
| **X·ª≠ l√Ω** | Spark Streaming + MLlib | Pandas + Transformers |
| **L∆∞u tr·ªØ** | MongoDB | CSV Files |
| **Tri·ªÉn khai** | Distributed cluster | Single machine |
| **Ph·ª©c t·∫°p** | High | Low |
| **Kh·∫£ nƒÉng m·ªü r·ªông** | High | Medium |

## K·∫øt qu·∫£ D·ª± ki·∫øn

D·ª±a tr√™n ƒë·ªì √°n g·ªëc, ch√∫ng ta d·ª± ki·∫øn:
- **Accuracy**: ~82% (t∆∞∆°ng ƒë∆∞∆°ng k·∫øt qu·∫£ g·ªëc)
- **Processing time**: Nhanh h∆°n do kh√¥ng c√≥ overhead c·ªßa distributed system
- **Resource usage**: Th·∫•p h∆°n ƒë√°ng k·ªÉ

## Troubleshooting

### L·ªói th∆∞·ªùng g·∫∑p

1. **ImportError: No module named 'transformers'**
   ```bash
   # ƒê·∫£m b·∫£o ƒëang trong virtual environment
   .venv\Scripts\Activate.ps1
   pip install transformers torch
   ```

2. **ModuleNotFoundError: No module named 'torch'**
   ```bash
   # C√†i ƒë·∫∑t PyTorch
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
   # Ho·∫∑c v·ªõi GPU support:
   # pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
   ```

3. **API Key kh√¥ng h·ª£p l·ªá**
   - Ki·ªÉm tra file `.env` c√≥ t·ªìn t·∫°i
   - ƒê·∫£m b·∫£o API key t·ª´ twitterapi.io ƒë√∫ng format
   - Ki·ªÉm tra quy·ªÅn c·ªßa API key

4. **CUDA out of memory (n·∫øu d√πng GPU)**
   ```python
   # Trong config.py, gi·∫£m BATCH_SIZE
   BATCH_SIZE = 8  # t·ª´ 32 xu·ªëng 8
   ```

5. **Rate limit exceeded**
   ```python
   # TƒÉng RATE_LIMIT_DELAY trong config.py
   RATE_LIMIT_DELAY = 5  # t·ª´ 2s l√™n 5s
   ```

6. **SSL Certificate errors**
   ```bash
   # N·∫øu g·∫∑p l·ªói SSL khi download model
   pip install --upgrade certifi
   # Ho·∫∑c set environment variable
   set CURL_CA_BUNDLE=""
   ```

7. **Permission denied khi t·∫°o virtual environment**
   ```bash
   # Ch·∫°y PowerShell as Administrator
   Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
   ```

## Development

### Ch·∫°y tests
```bash
cd src
python -m pytest tests/  # (n·∫øu c√≥)
```

### Test t·ª´ng module
```bash
python config.py      # Test configuration
python crawler.py     # Test data collection
python data_preprocessing.py  # Test preprocessing
python sentiment_analysis.py  # Test sentiment model
python visualization.py      # Test charts
```

## K·∫ø ho·∫°ch t∆∞∆°ng lai

- [ ] Th√™m m√¥ h√¨nh Logistic Regression ƒë·ªÉ so s√°nh
- [ ] H·ªó tr·ª£ nhi·ªÅu ng√¥n ng·ªØ
- [ ] Real-time dashboard v·ªõi Streamlit
- [ ] Docker containerization
- [ ] Cloud deployment (AWS/Azure)
- [ ] A/B testing framework

## ƒê√≥ng g√≥p

1. Fork repository
2. T·∫°o feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. T·∫°o Pull Request

## License

MIT License - xem file LICENSE ƒë·ªÉ bi·∫øt chi ti·∫øt

## T√°c gi·∫£

- **ThanhCongNguyen-2310373** - *Main Developer* - [GitHub](https://github.com/ThanhCongNguyen-2310373)
- **Tham kh·∫£o**: ƒê·ªì √°n c·ªßa Th·ªãnh L√¢m T·∫•n - Twitter Sentiment Analysis using Big Data

## Demo v√† K·∫øt qu·∫£

### üìä Sample Results (Demo Data)
- **T·ªïng tweets ph√¢n t√≠ch**: 75
- **Sentiment Distribution**:
  - üü¢ Positive: 80% (60 tweets)
  - üî¥ Negative: 13.33% (10 tweets)
  - ‚ö™ Neutral: 6.67% (5 tweets)
- **Average Sentiment Score**: 0.818/1.0
- **Processing Time**: ~22 seconds
- **Model Used**: cardiffnlp/twitter-roberta-base-sentiment-latest

### üìà Generated Outputs
- **Visualization Charts**: PNG format (overall, by-keyword, timeline)
- **Interactive Dashboard**: HTML v·ªõi Plotly
- **Processed Data**: CSV v·ªõi sentiment scores
- **Statistics**: JSON summary report

## Acknowledgments

- C·∫£m ∆°n anh Th·ªãnh L√¢m T·∫•n v√¨ ƒë·ªì √°n tham kh·∫£o xu·∫•t s·∫Øc
- Hugging Face team v√¨ m√¥ h√¨nh RoBERTa-Twitter
- Cardiff NLP team v√¨ pre-trained model
- twitterapi.io v√¨ API service

---

*D·ª± √°n n√†y ƒë∆∞·ª£c th·ª±c hi·ªán nh∆∞ m·ªôt ph·∫ßn c·ªßa kh√≥a h·ªçc NLP, t√°i hi·ªán v√† m·ªü r·ªông nghi√™n c·ª©u v·ªÅ sentiment analysis v·ªõi approach ƒë∆°n gi·∫£n h√≥a nh∆∞ng v·∫´n ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng k·∫øt qu·∫£.*